## L6 Thinking
**1.奇异值分解SVD的原理是怎样的，都有哪些应用场景**     
一般的方阵可以进行特征分解，分解成 特征矩阵X特征值的对角阵X特征矩阵的逆 这种形式。非方阵不能特征分解，但是用相似的原理可以对非方阵进行奇异值分解SVD。假设我们的矩阵A是一个m×n的矩阵，那么我们定义矩阵A的SVD为：
A=UΣVT  　其中U是一个m×m的矩阵，Σ是一个m×n的矩阵，除了主对角线上的元素以外全为0，主对角线上的每个元素都称为奇异值，V是一个n×n的矩阵。U和V都是正交矩阵（酉矩阵）。U，Σ，V的求解过程是：先求A乘以A的转置，这是一个方阵，对它进行特征分解得到AAT=U*D*UT，D就是AAT的特征值组成的对角矩阵。Σ就是D中特征值开根号得到奇异值组成的对角阵。同理求A的转置乘以A得出V。     
应用：奇异值组成的对角矩阵中对应的奇异值应当从大到小进行排列。对于推荐系统，已知一个user item的评分矩阵是mxn的，是非稀疏的，可以对缺失值用平均值方法进行补全，然后求SVD分解，选取前K的奇异值作为特征量Am×n=Um×k Σk×k VTk×n这是一种降维处理，也可以过滤噪音。同样对于一张原始信息较大的图片，我们可以用相同的方法SVD分解，选取前K个奇异值来对图像进行特征抽取，简化图像过滤噪声。


**2.funkSVD, BiasSVD，SVD++算法之间的区别是怎样的**
* funkSVD类似一般的user item矩阵分解：构造k个隐分类然后把原矩阵分解成两个矩阵相乘的形式
Mm×n=Pm×k × Qk×n    用梯度下降法最小化损失函数：![](2.png)   

* BiasSVD  在funkSVD的基础上引入baseline算法思想，设置用户偏好和商品偏好。评分的组成变为![](3.png)      
损失函数变为![](4.png) 同样可以用梯度下降法求解。

* SVD++ 在BiasSVD的基础上进一步考虑了用户的隐式反馈。用户的隐式行为比如点击浏览收藏等等没有评分，但可以贡献到对评分的预测中。
需要优化的目标函数更新为![](5.png) 



**3.矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足**  
应用场景一般是基于现有的用户和商品之间的一些数据，生成评分矩阵，这个矩阵有多种分解方式，我们通过优化算法求解分解后的矩阵，得到了分解后的矩阵，就可以还原完整的评分矩阵，获得了用户对所有商品的评分，选择高分的商品推荐给用户，可以根据以往的评分矩阵做全局的评分优化。  
不足是只考虑user,item的特征，本身特征维度比较少。


**4.item流行度在推荐系统中有怎样的应用**    
最常见的就是将最流行的内容推荐给用户，对于新用户的冷启动问题，采用非个性化推荐，根据流行度推荐。但是也要考虑推荐的多样性，多方面覆盖用户的兴趣。适当推荐流行度低的内容，并收集用户的反馈更能了解用户独特的兴趣。当使用协同过滤或相似度推荐对老用户进行推荐的时候，应当对流行度进行降权，推荐相似度更高，流行度更低的内容，挖掘长尾。


**5.推荐系统的召回阶段都有哪些策略**

* 以内容为索引召回 当日热点，地域热点等
* 以用户为索引召回 用户兴趣相关，相似用户兴趣
* 以设备为索引召回 用户机器设备对应群体热点，网络IP地址对应群体热点等







